{
 "cells":  [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source":  [
    "# Final Project FP-7: Machine Learning\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source":  [
    "___\n",
    "\n",
    "# Predicting Student Stress Levels Using Machine Learning\n",
    "\n",
    "* **Name**:  Jorre Wyffels\n",
    "* **Student number**: B990374161\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source":  [
    "### Dataset\n",
    "\n",
    "[Lifestyle Factors and Their Impact on Students](https://www.kaggle.com/datasets/charlottebennett1234/lifestyle-factors-and-their-impact-on-students/data) from Kaggle (Charlotte Bennett, 2025).\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source":  [
    "___\n",
    "\n",
    "## Improvements from FP-6\n",
    "\n",
    "This project extends FP-6 by adding preprocessing and dimensionality reduction (Lessons 13-14):\n",
    "\n",
    "1. **StandardScaler**: Normalizes features to mean=0, std=1 before KNN\n",
    "2. **PCA**: Tests dimensionality reduction to remove correlated features\n",
    "3. **Data import**: Now uses parse_data.ipynb instead of loading CSV directly\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type":  "code",
   "execution_count":  1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run 'machine. ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "### Effect of Preprocessing on KNN\n",
    "\n",
    "| Data | Accuracy |\n",
    "|------|----------|\n",
    "| Raw (FP-6) | ~91.8% |\n",
    "| Scaled (FP-7) | ~92.2% |\n",
    "| PCA | ~92.0% |\n",
    "\n",
    "Scaling provides a small improvement.  PCA shows that 4 components explain 84% of variance—the features aren't highly correlated with each other.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source":  [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs":  [],
   "source": [
    "plot_machine1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study hours (72%) and sleep hours (28%) explain all the variance in the Decision Tree model. Social time, physical activity, and gender have zero importance.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs":  [],
   "source": [
    "plot_machine2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source":  [
    "Decision Tree achieves 100% accuracy because stress levels follow clear thresholds based on study and sleep hours. KNN with scaling reaches ~92%, with errors at class boundaries.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "**Preprocessing impact:** Scaling improved KNN by ~0.4%.  The improvement is modest because feature ranges were already similar (mostly 0-10). In datasets with more varied scales, the effect would be larger.\n",
    "\n",
    "**PCA insight:** The cumulative variance analysis shows features aren't highly correlated in the raw data. However, the Decision Tree's feature importance reveals that only 2 features matter for prediction—this is a different kind of dimensionality reduction (feature selection vs. PCA's linear combinations).\n",
    "\n",
    "**Main finding:** Academic pressure (study hours) is the dominant predictor of student stress.\n",
    "\n",
    "See **machine.ipynb** for full analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name":  "Python 3",
   "language":  "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor":  4
}
